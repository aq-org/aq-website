---
publishDate: 2024-07-22T16:50:00+08:00
title: 人工智能(AI)时代的矛盾与对策 - AQ
excerpt: 人工智能(Artificial Intelligence，AI)于 1956 年被正式提出，经历了 60 多年的发展，如 今在文本翻译，文字识别，智能安防等诸多领域发挥了重要作用。但自从 2022 年 11 月 30 日，OpenAI 公司推出一款人工智能对话聊天机器人 ChatGPT 后，众多出色的自然语言生 成模型引起了全世界范围的广泛关注，人们对于 AI 的安全产生了不少的担忧。 本文列举 了 AI 时代的多个显著问题，对于这些问题进行了分析，分别提出了不同的对策。研究表 明，AI 目前所遇到的问题，正如每一次工业革命时所遇到的问题。一方面 AI 已经带来了 生产力的提升，但另一方面各种问题层出不穷。AI 发展的阻碍未能解决并将长期存在。 只有挺过质疑，解决 AI 发展的阻碍，人类才能真正迎来 AI 的突破，走进 AI 时代。
image: https://www.axa6.com/aq.png
category: Blog
tags:
  - AQ
  - Blog
metadata:
  canonical: https://www.axa6.com/zh/contradictions-and-countermeasures-in-the-era-of-artificial-intelligence
---

# 人工智能(AI)时代的矛盾与对策
## 简介
*人工智能(Artificial Intelligence，AI)*于`1956`年被正式提出，经历了60多年的发展，如今在`文本翻译`，`文字识别`，`智能安防`等诸多领域发挥了重要作用。但自从`2022年11月30日`，`OpenAI 公司`推出一款人工智能对话聊天机器人 `ChatGPT` 后，众多出色的*自然语言生成模型*引起了全世界范围的广泛关注，人们对于 `AI` 的`安全`产生了不少的担忧。本文列举了 `AI` 时代的多个显著问题，对于这些问题进行了分析，分别提出了不同的对策。得出结论，`AI` 目前所遇到的问题，正如每一次工业革命时所遇到的问题。一方面 `AI` 已经带来了生产力的提升，但另一方面各种问题层出不穷。`AI` 发展的阻碍未能解决并将长期存在。只有挺过质疑，解决 `AI` 发展的阻碍，人类才能真正迎来 `AI` 的突破，走进 `AI` 时代。</br>

## 正文
*人工智能(Artificial Intelligence，AI)*于`1956`年被正式提出，经历了60多年的发展，如今在`文本翻译`，`文字识别`，`智能安防`等诸多领域发挥了重要作用。但自从`2022年11月30日`，`OpenAI 公司`推出一款人工智能对话聊天机器人`ChatGPT`后，众多出色的*自然语言生成模型*引起了全世界范围的广泛关注，人们对于 `AI` 的安全产生了不少的担忧。数据与隐私安全风险，`AI` 诈骗，生成内容**帮助或违反道德和法律**，**存在歧视与偏见**，**就业与社会问题**以及不少研究人员和学者所担心的终极问题: **`AI` 失控**。现阶段的 `AI` 模型大多均基于 `Transformer` 或类似原理。通过 `Transformer` 实现 `AI` 的过程分为`编码`和`解码`。`编码`过程就是 `AI` 学习过程的重中之重。`AI` 所掌握的技能，如`翻译`，`绘图`，`识别`等，都是通过该过程之后获得的`权重`实现的。之后通过`Self-Attention`，`Multi-Head Attention`，`Add & Norm`等解码过程，`AI` 模型就具有了根据输入，输出对应内容的能力。因此基于`Transformer`的 `AI` ，本质上也可以理解为一个通过输入，根据`权重`的数据进行计算，最终获得输出的`程序`。</br>

最受关注的问题就是 `AI` 的**非法使用问题**。目前的 `AI` 所获得的能力，均来源于*训练时的数据*。从理论上说，未经过二次改进的 `AI` 模型的能力自 `AI` 创建后就不会改变。因此，在 `AI` 训练时对训练数据进行排查是极其必要的。适当在模型训练数据中加入错误输入和纠正的输出，可以提高 `AI` 模型的对非法内容的鉴别能力。对于 `AI` 模型的非法输出，并非 `AI` 模型的运行问题，在 `AI` 模型的运行中，计算输入与权重始终是准确无误的，出现问题的部分有且仅有可能是`权重`。因此在一定程度上，可以将 `AI` 模型的非法输出类比为程序的`缺陷(bug)`。但由于 `AI` 模型*训练过程无法控制*，*`权重`难以进行修改*，整个运行过程类似`黑箱`。但该问题也并非无法解决。对于 `AI` 的管控，分为`训练前`和`训练后`。在 `AI` 训练后，对于 `AI` 内容进行输出的`审查`，如设置另一个专门的 `AI` 审查模型，同样是有效的。可以从另一角度避免 `AI` 模型的非法输出。`AI` 输出的安全风险难以避免，但可以通过各种手段减弱或降低。随着 `AI` 模型训练成本的不断降低，有人使用 `AI` 模型进行违法犯罪是难以避免的。因此，对于现有的 `AI` 模型，**不应该一味暂停或阻碍研发**。使用更新的 `AI` 技术**对抗非法用途**可以起到更好的效果。反之则会因为固步自封，落后于科技进步的潮流。从另一个角度看待这个问题，在 `AI` 时代，`AI` 作为一种**新的技术**，本质上是为人类服务的，如今不少人将 `AI` 列为第四、五次工业革命也正从侧面证明了 `AI` 对于提高生产力可以发挥重要作用。因此如果因为对于部分安全原因的担忧，就放弃对于 `AI` 的研发和使用，不仅无法起到**阻止违法**的目的，同时会因此放弃一次重大的生产工具的革新。换而言之，对于*黑产等违法犯罪团体*来说，放弃*研发和提供目前的模型*并不能**阻止违法犯罪活动**，只能提升非法活动的难度。`AI` 如同·潘多拉的魔盒·，一旦打开就没有挽回的可能。因此相较于因此造成的损失，将目标放在加紧 `AI` 研发和非法输出审查的研究上，对于 `AI` 的发展更加有利。从 `AI` 的安全性来看，`AI` 既存在风险，又有一定的防御措施，对于如今的 `AI` 提供商来说，如何平衡 `AI` 的安全与智能，成为了一个难以解决的矛盾。</br>

另一个备受关注的问题是 `AI` 输出的准确性。在`ChatGPT`刚开放对外服务时，人们因为新鲜而争相体验，而经过1年多的发展，如今 `AI` 已经迎来了*竞争和淘汰*。`AI` 的用途也由兴趣转向了生产力。在生产领域上，`AI` 相较于人工具有很强的竞争力。不仅使用成本低，同时可以支持247365的服务，而又不会具有人工的缺点。但在目前的生产使用中，`AI` 模型成也`Transformer`，败也`Transformer`。毫无疑问的是，基于`Transformer`的模型具有很强的*NLP(Natural Language Processing，自然语言处理)*能力，但对于*数学运算和未经或较少训练的内容*，可能出现幻觉(错误)。对于这样的问题，在技术未能实现重大突破的时候，只能通过互联网的搜索和增加训练数据实现。因此在现阶段的生产中，`AI` 更多作为辅助而非主导。在目前的 `AI` 中，通过增加工具(如`python运行`，`计算器`等)以供 `AI` 使用可以解决一部分的幻觉问题，但即使在未来 `AI` 发展后，除非技术出现了更新，能够完全确认 `AI` 的运行不会出现任何问题，否则在重要的领域，人类必须始终作为`监督者`，确认 `AI` 的安全运行。因此从这个角度说，`AI` 在现阶段不应该独立操作任何设备运行。否则，即使不会出现所谓的“自主意识”，出现了`缺陷(bug)`也可能造成不可挽回的损失。一方面，`AI` 拥有智能，可以提升`生产力`，但另一方面，`AI` 又可能造成`损失`。因此在 `AI` 运行设备的问题上，`AI` 的智能与人类的监督成为了如今不少领域的冲突。</br>

在 `AI` 的生产领域，**数据与隐私的安全**同样重要。由于目前的 `AI` 对于算力的要求高于本地化设备，对于 `AI` 本地化的要求和投入较高，难以实现全部本地化。因此对于 `AI` 公司和使用者来说，这样反而是目前所遇到的难题之一。对于使用过程中的传输内容，可能会造成数据泄露和隐私问题。如今对于许多隐私数据，`AI` 的部署成本与数据安全成为了难以实现的矛盾。</br>

在文本，图片和视频生成领域，**版权问题**也是目前 `AI` 所遇到的重要问题之一。目前不同国家的法律对 `AI` 生成内容的版权有不同的判例。但从单一角度说，`AI` 生产内容的版权可以视为一种辅助创作的工具，如果 `AI` 的源代码和训练数据均来自作者，那么 `AI` 生产内容的版权不会有任何质疑。但目前的版权问题来自于 `AI` 的源码和训练数据均不来自单一作者，甚至基本全都未获得著作权授权。之前曾出现某 `AI` 模型经过诱导后输出了原始训练数据，由于该训练数据均含有版权且 `AI` 公司未获得授权，因此被版权方起诉。由此可以发现 `AI` 因此对于训练数据进行计算，得到权重，可以在一定程度上将权重认为是对于训练数据的压缩等修改，那么输出可以视为对于部分训练数据的改编，因此存在版权的相关问题。因此在此类问题上，使用 `AI` 生成内容的著作权仍难以确认。这作为目前 `AI` 所遇到的重要问题，使生成领域的 `AI` 无法被广泛应用。在版权领域，`AI` 的效率与版权成为了难以选择的冲突。</br>

对于上面两个问题，最好的解决方案是加快 `AI` 的发展，使 `AI` 训练能够降低成本，实现本地化部署。相较于这个问题，对于许多人的担忧: `AI` 越来越智能，未来会取代人类。是一个容易回答却难以短时间改变观念的问题。</br>
目前经过1年的时间，从`GPT-3.5`到`GPT-4o`，`AI` 毫无疑问越来越智能。在许多人眼里，*AGI（Artificial General Intelligence，人工通用智能）*已经不远，但 `AI` 的安全性难以保证。对于这个问题，只要 `AI` 的训练数据能够加以控制，`AI` 的控制权能够存在监督，`AI` 就不会产生较大危害。但对于许多 `AI` 能快速替代且不会造成严重损失的岗位，或许将成为时代发展的最早牺牲。人类的能力来自于持续不断的学习。通过对于现实世界的不断接触(无论是语言，声音还是图像)，不断积累记忆和思考能力。因此相较于目前 `AI` 的能力训练后不再增加，能力是多样且有上升空间的。即使在未来 `AI` 拥有更强的学习能力，只要能监督 `AI` 的训练数据的主流观念，也就可以对 `AI` 所谓的“意识”加以控制。例如: `AI` 从互联网的数据进行训练，那么 `AI` 的“意识”来自于互联网的主流观念。因此在一定程度上说，对于 `AI` 失控的担忧就是不必的。但在人们的观念中，`AI` 具有不少电影里神乎其神的能力，并且在迅速发展，还可以替代一部分的岗位。因此除了 `AI` 本身的问题，**人们的观念与现实的情况**也成为了 `AI` 时代之初的矛盾。</br>

**电力，水力等基础设施**也成为了 `AI` “军备竞赛”中极其重要的部分。但由于目前全球气候变暖，水资源匮乏，保护环境已经成为全人类的常态。但如今 `AI` 对于水电的需求已经超出了预期。在这样的情况下，`AI` 的需求与环境的问题成为了 `AI` 时代发展的冲突。如今对 `AI` 进行改进和提升，使 `AI` 对于资源的需求更低，可能才是实现AGI和解决一切问题的根源。</br>

`AI` 目前所遇到的问题，正如每一次工业革命时所遇到的问题。毫无疑问，一方面 `AI` 已经带来了`生产力`的提升，但另一方面各种问题层出不穷。即使所有问题都有解决方法，仍会有新的质疑与阻碍。如今的质疑已经在 `AI` 的不断进步中化解，但 `AI` 发展的阻碍却未能解决并将长期存在。或许只有挺过质疑，解决 `AI` 发展的阻碍，人类才能真正迎来 `AI` 的突破，走进 `AI` 时代。</br>
